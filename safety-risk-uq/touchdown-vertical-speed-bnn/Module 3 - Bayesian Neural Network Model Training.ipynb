{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1dbf4a1",
   "metadata": {},
   "source": [
    "# Bayesian Neural Networks to Predict Hard Landing with DASHlink Data\n",
    "Authors: Dr. Yingxiao Kong, Vanderbilt University\n",
    "\n",
    "Email: yingxiao.kong@vanderbit.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cf4239",
   "metadata": {},
   "source": [
    "## Overview of Research\n",
    "In this work, we use an open-source dataset - [NASA's DASHlink data](https://c3.ndc.nasa.gov/dashlink/) - to isolate data for landing aircraft that both have hard landing and normal landing occurrences. The objective is to use [this sample data](https://c3.ndc.nasa.gov/dashlink/projects/85/resources/?type=ds) to train a Bayesian Neural Network model to predict touchdown vertical speed for a landing aircraft with the intent to use as a screening for identifying hard landing events before they occur.\n",
    "\n",
    "This series of Jupyter notebook demonstrations into 3 modules. The presented module is in **bold**:\n",
    "- Module 1 - Download DASHlink Data\n",
    "- Module 2 - DASHlink Data Pre-Processing and Feature Selection with Maximum Relevance and Minimum Reduandancy (MRMR)\n",
    "- **Module 3 - Bayesian Neural Network Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f3ab5",
   "metadata": {},
   "source": [
    "## Module 3: Bayesian Neural Network Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5d06d0",
   "metadata": {},
   "source": [
    "## Step 3a: Define Training Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40863252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(key_list,time_step):\n",
    "\n",
    "    array_new_data=np.zeros((len(all_new_data),time_step,len(key_list)))\n",
    "\n",
    "    for i in range(array_new_data.shape[0]):\n",
    "        for j in range(array_new_data.shape[2]):\n",
    "            key=key_list[j]\n",
    "            array_new_data[i,:,j]=all_new_data[i][key][:time_step]\n",
    "\n",
    "    RNN_x=np.zeros((array_new_data.shape))\n",
    "    ### RNN_x is normalized array_new_data\n",
    "\n",
    "    for i in range(RNN_x.shape[1]):\n",
    "        for j in range(RNN_x.shape[2]):\n",
    "            RNN_x[:,i,j]=(array_new_data[:,i,j]-np.min(array_new_data[:,i,j]))/(np.max(array_new_data[:,i,j])-np.min(array_new_data[:,i,j])+np.exp(-8))\n",
    "\n",
    "    RNN_y=np.array(all_td_altr)*0.3048/60\n",
    "\n",
    "    RNN_y_scale = np.log(RNN_y - min(RNN_y) + 1)\n",
    "    ### here we also scale down RNN_y_scale to make it eaiser to converge\n",
    "    delta=np.log(-2-min(RNN_y)+1)\n",
    "                                                                                \n",
    "    return RNN_x,RNN_y,RNN_y_scale,delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281c4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout,LSTM,Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import json\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c25ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_para=pd.read_csv('all_all_sele_fea_26_spearman.csv')\n",
    "all_para=all_para.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e6c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### key_list is the one used to do feature sorting and selection\n",
    "key_list=['DIST','LATP','LONP','MSQT_1','BAL1','TAS','GS','TH','FLAP','GLS','LOC','N1_1','PTCH','ROLL','TRK','AIL_1','RUDD','ELEV_1',\\\n",
    "         'BLAC','CTAC','FPAC','CCPC','CWPC','WS','WD','ALTR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "225c2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sele_key_list is the one used to generate the RNN_x\n",
    "sele_key_list=['CCPC','CTAC','PTCH','ELEV_1','BLAC','N1_1','GS','TAS','GLS','WS','ROLL','FPAC','WD','LONP','TH','LATP','DIST','AIL_1','LOC','TRK','BAL1','RUDD','FLAP','ALTR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13ee688",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_x = np.load('RNN_x_sele.npy')\n",
    "RNN_y = np.load('RNN_y.npy')\n",
    "RNN_y_mean = np.mean(RNN_y)\n",
    "RNN_y_std = np.std(RNN_y)\n",
    "stand_RNN_y = (RNN_y-RNN_y_mean)/(RNN_y_std)\n",
    "RNN_y_scale = np.load('RNN_y_scale.npy')\n",
    "RNN_y_scale_reverse = np.exp(RNN_y_scale)-1+np.min(RNN_y)\n",
    "\n",
    "diff = np.mean(RNN_y)-np.mean(RNN_y_scale_reverse)\n",
    "\n",
    "key_list=['DIST','LATP','LONP','MSQT_1','BAL1','TAS','GS','TH','FLAP','GLS','LOC','N1_1','PTCH','ROLL','TRK','AIL_1','RUDD','ELEV_1',\\\n",
    "         'BLAC','CTAC','FPAC','CCPC','CWPC','WS','WD','ALTR']\n",
    "### the difference between key_list and final_key_list is that key_list include latp and lonp\n",
    "height_list=np.array([200,100,50,40,30,20,10,8,6,4,2])\n",
    "\n",
    "\n",
    "def train_data(RNN_x,num_parameter):\n",
    "    return (RNN_x[:,:,:num_parameter])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce6088c",
   "metadata": {},
   "source": [
    "### Step 3b: Define RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNN_model(in_shape, idrop=0.25, odrop=0.25, rdrop=0.25, weight_decay=1e-4, lr=1e-3,num_unit=100):\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(num_unit,kernel_regularizer=l2(weight_decay),recurrent_regularizer=l2(weight_decay),bias_regularizer=l2(weight_decay),dropout=idrop,recurrent_dropout=rdrop,input_shape=(None,in_shape),\\\n",
    "                  kernel_initializer='random_uniform',return_sequences=True))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(LSTM(num_unit,dropout=idrop,recurrent_dropout=rdrop,return_sequences=False,kernel_regularizer=l2(weight_decay),recurrent_regularizer=l2(weight_decay),bias_regularizer=l2(weight_decay),kernel_initializer='random_uniform',))\n",
    "    model.add(Activation('relu'))\n",
    "    if odrop:\n",
    "        model.add(Dropout(odrop))\n",
    "    model.add(Dense(1,activation='linear',kernel_regularizer=l2(weight_decay),bias_regularizer=l2(weight_decay)))\n",
    "    optimizer_=Adam(lr)\n",
    "    #in the paper variational dropout, learning rate isn't considered\n",
    "#     optimizer=Adam\n",
    "    model.compile(loss='mse',metrics=['mse'],optimizer=optimizer_)\n",
    "    return model\n",
    "\n",
    "def get_RNN_model_2(in_shape, idrop=0.25, odrop=0.25, rdrop=0.25, weight_decay=1e-4, lr=1e-3,num_unit=100):\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(num_unit,kernel_regularizer=l1(weight_decay),recurrent_regularizer=l1(weight_decay),bias_regularizer=l1(weight_decay),dropout=idrop,recurrent_dropout=rdrop,input_shape=(None,in_shape),\\\n",
    "                  kernel_initializer='random_uniform',return_sequences=True))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(LSTM(num_unit,dropout=idrop,recurrent_dropout=rdrop,return_sequences=False,kernel_regularizer=l1(weight_decay),recurrent_regularizer=l1(weight_decay),bias_regularizer=l1(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    if odrop:\n",
    "        model.add(Dropout(odrop))\n",
    "    model.add(Dense(1,activation='linear',kernel_regularizer=l1(weight_decay),bias_regularizer=l1(weight_decay)))\n",
    "    optimizer_=Adam(lr)\n",
    "    #in the paper variational dropout, learning rate isn't considered\n",
    "#     optimizer=Adam\n",
    "    model.compile(loss='mse',metrics=['mse'],optimizer=optimizer_)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "\n",
    "class KerasDPprediction(object):\n",
    "    def __init__(self,model):\n",
    "        self.f= K.function([model.layers[0].input,K.learning_phase()],[model.layers[-1].output])\n",
    "        \n",
    "    def predict(self,x,n_iter=1000):\n",
    "        result=[]\n",
    "        for _ in range(n_iter):\n",
    "            result.append(np.squeeze(self.f([x,1])))\n",
    "        result = np.array(result)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcdfb7",
   "metadata": {},
   "source": [
    "### Step 3c: Train RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041d0a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j: 0\n",
      "i: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 15:00:57.417257: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-30 15:00:57.459450: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 15:00:57.531969: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (lstm/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     RNN_x_train,RNN_x_test,RNN_y_train,RNN_y_test\u001b[38;5;241m=\u001b[39mtrain_test_split(partial_data[:,:,:], RNN_y_scale_reverse, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#     RNN_x_train,RNN_x_test,RNN_y_train,RNN_y_test=train_test_split(partial_data[:,:,:],RNN_y, test_size=0.2, random_state=40)\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     RNN_model \u001b[38;5;241m=\u001b[39m \u001b[43mget_RNN_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRNN_x_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     RNN_model\u001b[38;5;241m.\u001b[39mfit(RNN_x_train,RNN_y_train,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     32\u001b[0m     kdp \u001b[38;5;241m=\u001b[39m KerasDPprediction(RNN_model)\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mget_RNN_model\u001b[0;34m(in_shape, idrop, odrop, rdrop, weight_decay, lr, num_unit)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_RNN_model\u001b[39m(in_shape, idrop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, odrop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, rdrop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,num_unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m     29\u001b[0m     model\u001b[38;5;241m=\u001b[39mSequential()\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_unit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrecurrent_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbias_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midrop\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrdrop\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43min_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom_uniform\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     35\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(LSTM(num_unit,dropout\u001b[38;5;241m=\u001b[39midrop,recurrent_dropout\u001b[38;5;241m=\u001b[39mrdrop,return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,kernel_regularizer\u001b[38;5;241m=\u001b[39ml2(weight_decay),recurrent_regularizer\u001b[38;5;241m=\u001b[39ml2(weight_decay),bias_regularizer\u001b[38;5;241m=\u001b[39ml2(weight_decay),kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m,))\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:517\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 517\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:208\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    203\u001b[0m     x \u001b[38;5;241m=\u001b[39m input_layer\u001b[38;5;241m.\u001b[39mInput(\n\u001b[1;32m    204\u001b[0m         batch_shape\u001b[38;5;241m=\u001b[39mbatch_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mlayer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# This will build the current layer\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m# and create the node connecting the current layer\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# to the input layer we just created.\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     set_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_inputs:\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:660\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m inputs, initial_state, constants \u001b[38;5;241m=\u001b[39m _standardize_args(inputs,\n\u001b[1;32m    655\u001b[0m                                                      initial_state,\n\u001b[1;32m    656\u001b[0m                                                      constants,\n\u001b[1;32m    657\u001b[0m                                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_constants)\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 660\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:951\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 951\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    955\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1090\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keras_tensor\u001b[38;5;241m.\u001b[39mkeras_tensors_enabled():\n\u001b[1;32m   1087\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m   1088\u001b[0m       layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1090\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1095\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1096\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:822\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:863\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    858\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# overridden).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m--> 863\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[1;32m    867\u001b[0m                         build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1157\u001b[0m, in \u001b[0;36mLSTM.call\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args_if_ragged(is_ragged_input, mask)\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# LSTM does not support constants. Ignore it during process.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m inputs, initial_state, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m   1160\u001b[0m   mask \u001b[38;5;241m=\u001b[39m mask[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:859\u001b[0m, in \u001b[0;36mRNN._process_inputs\u001b[0;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[1;32m    857\u001b[0m     initial_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m   initial_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_initial_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(initial_state) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates):\n\u001b[1;32m    862\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer has \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates)) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    863\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m states but was passed \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(initial_state)) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    864\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m initial states.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:642\u001b[0m, in \u001b[0;36mRNN.get_initial_state\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    640\u001b[0m dtype \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_initial_state_fn:\n\u001b[0;32m--> 642\u001b[0m   init_state \u001b[38;5;241m=\u001b[39m \u001b[43mget_initial_state_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    645\u001b[0m   init_state \u001b[38;5;241m=\u001b[39m _generate_zero_filled_state(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell\u001b[38;5;241m.\u001b[39mstate_size,\n\u001b[1;32m    646\u001b[0m                                            dtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2506\u001b[0m, in \u001b[0;36mLSTMCell.get_initial_state\u001b[0;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[1;32m   2505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_initial_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 2506\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43m_generate_zero_filled_state_for_cell\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2507\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2987\u001b[0m, in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[0;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[1;32m   2985\u001b[0m   batch_size \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(inputs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2986\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m-> 2987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_generate_zero_filled_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:3003\u001b[0m, in \u001b[0;36m_generate_zero_filled_state\u001b[0;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[1;32m   3000\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39mzeros(init_state_size, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   3002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mis_nested(state_size):\n\u001b[0;32m-> 3003\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_zeros\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3005\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m create_zeros(state_size)\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:3000\u001b[0m, in \u001b[0;36m_generate_zero_filled_state.<locals>.create_zeros\u001b[0;34m(unnested_state_size)\u001b[0m\n\u001b[1;32m   2998\u001b[0m flat_dims \u001b[38;5;241m=\u001b[39m tensor_shape\u001b[38;5;241m.\u001b[39mTensorShape(unnested_state_size)\u001b[38;5;241m.\u001b[39mas_list()\n\u001b[1;32m   2999\u001b[0m init_state_size \u001b[38;5;241m=\u001b[39m [batch_size_tensor] \u001b[38;5;241m+\u001b[39m flat_dims\n\u001b[0;32m-> 3000\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2819\u001b[0m, in \u001b[0;36m_tag_zeros_tensor.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2819\u001b[0m   tensor \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2820\u001b[0m   tensor\u001b[38;5;241m.\u001b[39m_is_zeros_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2821\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2868\u001b[0m, in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2864\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2865\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m   2866\u001b[0m     \u001b[38;5;66;03m# Create a constant if it won't be very big. Otherwise create a fill\u001b[39;00m\n\u001b[1;32m   2867\u001b[0m     \u001b[38;5;66;03m# op to prevent serialized GraphDefs from becoming too large.\u001b[39;00m\n\u001b[0;32m-> 2868\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_constant_if_small\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzero\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2870\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2804\u001b[0m, in \u001b[0;36m_constant_if_small\u001b[0;34m(value, shape, dtype, name)\u001b[0m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_if_small\u001b[39m(value, shape, dtype, name):\n\u001b[1;32m   2803\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[1;32m   2805\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m constant(value, shape\u001b[38;5;241m=\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   2806\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;66;03m# Happens when shape is a Tensor, list with Tensor elements, etc.\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3045\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2929\u001b[0m          initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2930\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2931\u001b[0m \u001b[38;5;124;03m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[1;32m   2932\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3043\u001b[0m \u001b[38;5;124;03m    10\u001b[39;00m\n\u001b[1;32m   3044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3046\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paraatm/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:852\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 852\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    853\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert a symbolic Tensor (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) to a numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    854\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This error may indicate that you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre trying to pass a Tensor to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    855\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a NumPy call, which is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (lstm/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "## here we're using the last column of the parameters to train the model\n",
    "# final_RNN_x = RNN_x[:,:,final_para_index[:,-1]]\n",
    "sele_key_list=['CCPC','CTAC','PTCH','ELEV_1','BLAC','N1_1','GS','TAS','GLS','WS','ROLL','FPAC','WD','LONP','TH','LATP','DIST','AIL_1','LOC','TRK','BAL1','RUDD','FLAP','ALTR']\n",
    "\n",
    "all_all_result = []\n",
    "all_all_RMSE=[]\n",
    "all_all_MAE = []\n",
    "\n",
    "for j in range(1):\n",
    "    print('j: '+str(j))\n",
    "    sort_index = []\n",
    "    sele_col = 2\n",
    "    ### sele_col: 0-4\n",
    "    for i in range(all_para.shape[0]):\n",
    "        if all_para[i,sele_col] in sele_key_list:\n",
    "            sort_index.append(sele_key_list.index(all_para[i,sele_col]))\n",
    "#     sort_index = np.insert(sort_index,0,23)\n",
    "\n",
    "    final_RNN_x = RNN_x[:,:,sort_index]\n",
    "    all_result=[]\n",
    "    all_RMSE=[]\n",
    "    all_MAE = []\n",
    "    for i in np.arange(4,28,4):\n",
    "        print('i: '+str(i))\n",
    "        ### i is the number of parameters taken to construct the training model\n",
    "        partial_data = train_data(final_RNN_x,i)\n",
    "        #### the model is trained based on RNN_y_scale_reverse\n",
    "        RNN_x_train,RNN_x_test,RNN_y_train,RNN_y_test=train_test_split(partial_data[:,:,:], RNN_y_scale_reverse, test_size=0.2, random_state=40)\n",
    "    #     RNN_x_train,RNN_x_test,RNN_y_train,RNN_y_test=train_test_split(partial_data[:,:,:],RNN_y, test_size=0.2, random_state=40)\n",
    "        RNN_model = get_RNN_model(RNN_x_train.shape[2])\n",
    "        RNN_model.fit(RNN_x_train,RNN_y_train,batch_size=30,verbose=False,epochs=200)\n",
    "        kdp = KerasDPprediction(RNN_model)\n",
    "        y_test_pred=kdp.predict(RNN_x_test,1000)\n",
    "        all_result.append(y_test_pred)\n",
    "        mean_y_test_pred = np.mean(y_test_pred,axis=0)\n",
    "        RMSE =np.sqrt(np.mean((mean_y_test_pred-RNN_y_test)**2)) \n",
    "        MAE = np.mean(np.abs(mean_y_test_pred-RNN_y_test))\n",
    "\n",
    "        all_RMSE.append(RMSE)\n",
    "        all_MAE.append(MAE)\n",
    "    all_all_result.append(all_result)\n",
    "    all_all_RMSE.append(all_RMSE)\n",
    "    all_all_MAE.append(all_MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54a95f",
   "metadata": {},
   "source": [
    "### Step 3d: Assessment of Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d21184a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ec49ddd320>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_all_MAE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616e950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
