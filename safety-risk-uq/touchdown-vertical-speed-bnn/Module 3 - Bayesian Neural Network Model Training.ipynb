{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1dbf4a1",
   "metadata": {},
   "source": [
    "# Bayesian Neural Networks to Predict Hard Landing with DASHlink Data\n",
    "Authors: Dr. Yingxiao Kong, Vanderbilt University\n",
    "\n",
    "Email: yingxiao.kong@vanderbit.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cf4239",
   "metadata": {},
   "source": [
    "## Overview of Research\n",
    "In this work, we use an open-source dataset - [NASA's DASHlink data](https://c3.ndc.nasa.gov/dashlink/) - to isolate data for landing aircraft that both have hard landing and normal landing occurrences. The objective is to use [this sample data](https://c3.ndc.nasa.gov/dashlink/projects/85/resources/?type=ds) to train a Bayesian Neural Network model to predict touchdown vertical speed for a landing aircraft with the intent to use as a screening for identifying hard landing events before they occur.\n",
    "\n",
    "This series of Jupyter notebook demonstrations into 3 modules. The presented module is in **bold**:\n",
    "- Module 1 - Download DASHlink Data\n",
    "- Module 2 - DASHlink Data Pre-Processing and Feature Selection with Maximum Relevance and Minimum Reduandancy (MRMR)\n",
    "- **Module 3 - Bayesian Neural Network Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f3ab5",
   "metadata": {},
   "source": [
    "## Module 3: Bayesian Neural Network Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5d06d0",
   "metadata": {},
   "source": [
    "## Step 3a: Get Processed Data and Ordered Features from Module 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b60cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_landing =  pd.read_csv('processed_data_landing_at_msp.csv')\n",
    "df_features=pd.read_csv('ordered_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_landing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ae7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features\n",
    "inputs_list = df_features.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = 'TD_ALTR'\n",
    "INPUTS_LIST = df_features.iloc[:,0].values\n",
    "INPUTS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd859b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_landing = df_landing[list(INPUTS_LIST)+[OUTPUT]+['heights']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c4b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88e02ff7",
   "metadata": {},
   "source": [
    "### Step 3b: Define Training Inputs and Output Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(df,output='TD_ALTR',drop='heights'):\n",
    "    if 'heights' in df.columns:\n",
    "        df.drop(labels='heights',axis=1,inplace=True)\n",
    "    \n",
    "    df_in = df.drop(labels=output,axis=1)\n",
    "    df_out = df[output]\n",
    "    x_train = (df_in-df_in.min())/(df_in.max()-df_in.min())\n",
    "\n",
    "    y_train= df_out.values*0.3048/60\n",
    "\n",
    "    y_train_scale = np.log(y_train - min(y_train) + 1)\n",
    "    ### here we also scale down RNN_y_scale to make it eaiser to converge\n",
    "    delta=np.log(-2-min(y_train)+1)\n",
    "    \n",
    "    y_train_mean = np.mean(y_train)\n",
    "    y_train_std = np.std(y_train)\n",
    "    z_train = (y_train-y_train_mean)/(y_train_std)\n",
    "\n",
    "    y_train_scale_reverse = np.exp(y_train_scale)-1+np.min(y_train)\n",
    "\n",
    "    diff = np.mean(y_train)-np.mean(y_train_scale_reverse)\n",
    "                                                                                \n",
    "    return x_train,y_train,y_train_scale,delta,z_train,diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c2481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ee688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ce6088c",
   "metadata": {},
   "source": [
    "### Step 3c: Define RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout,LSTM,Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.models import Sequential\n",
    "\n",
    "def get_RNN_model(in_shape, idrop=0.25, odrop=0.25, rdrop=0.25, weight_decay=1e-4, lr=1e-3,num_unit=100):\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(num_unit,kernel_regularizer=l2(weight_decay),recurrent_regularizer=l2(weight_decay),bias_regularizer=l2(weight_decay),dropout=idrop,recurrent_dropout=rdrop,input_shape=(None,in_shape),\\\n",
    "                  kernel_initializer='random_uniform',return_sequences=True))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(LSTM(num_unit,dropout=idrop,recurrent_dropout=rdrop,return_sequences=False,kernel_regularizer=l2(weight_decay),recurrent_regularizer=l2(weight_decay),bias_regularizer=l2(weight_decay),kernel_initializer='random_uniform',))\n",
    "    model.add(Activation('relu'))\n",
    "    if odrop:\n",
    "        model.add(Dropout(odrop))\n",
    "    model.add(Dense(1,activation='linear',kernel_regularizer=l2(weight_decay),bias_regularizer=l2(weight_decay)))\n",
    "    optimizer_=Adam(lr)\n",
    "    #in the paper variational dropout, learning rate isn't considered\n",
    "#     optimizer=Adam\n",
    "    model.compile(loss='mse',metrics=['mse'],optimizer=optimizer_)\n",
    "    return model\n",
    "\n",
    "def get_RNN_model_2(in_shape, idrop=0.25, odrop=0.25, rdrop=0.25, weight_decay=1e-4, lr=1e-3,num_unit=100):\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(num_unit,kernel_regularizer=l1(weight_decay),recurrent_regularizer=l1(weight_decay),bias_regularizer=l1(weight_decay),dropout=idrop,recurrent_dropout=rdrop,input_shape=(None,in_shape),\\\n",
    "                  kernel_initializer='random_uniform',return_sequences=True))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(LSTM(num_unit,dropout=idrop,recurrent_dropout=rdrop,return_sequences=False,kernel_regularizer=l1(weight_decay),recurrent_regularizer=l1(weight_decay),bias_regularizer=l1(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    if odrop:\n",
    "        model.add(Dropout(odrop))\n",
    "    model.add(Dense(1,activation='linear',kernel_regularizer=l1(weight_decay),bias_regularizer=l1(weight_decay)))\n",
    "    optimizer_=Adam(lr)\n",
    "    #in the paper variational dropout, learning rate isn't considered\n",
    "#     optimizer=Adam\n",
    "    model.compile(loss='mse',metrics=['mse'],optimizer=optimizer_)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "\n",
    "class KerasDPprediction(object):\n",
    "    def __init__(self,model):\n",
    "        self.f= K.function([model.layers[0].input,K.learning_phase()],[model.layers[-1].output])\n",
    "        \n",
    "    def predict(self,x,n_iter=1000):\n",
    "        result=[]\n",
    "        for _ in range(n_iter):\n",
    "            result.append(np.squeeze(self.f([x,1])))\n",
    "        result = np.array(result)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcdfb7",
   "metadata": {},
   "source": [
    "### Step 3c: Train RNNs for Given MRMR Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07650f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_REDUNDANCY_WEIGHT = 0.5\n",
    "input_order=df_features.iloc[:,df_features.columns=='{}'.format(MIN_REDUNDANCY_WEIGHT)]\n",
    "print(input_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9150d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "grpby = df_landing.groupby(by='heights')\n",
    "NINPUTS = np.arange(4,24,4)\n",
    "print(NINPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = grpby.get_group(0)\n",
    "n = 4\n",
    "df[list(df.columns[:n])+[OUTPUT]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpby = df_landing.groupby(by='heights')\n",
    "NINPUTS = np.arange(4,24,4)\n",
    "for i,g in enumerate(grpby):\n",
    "    height = g[0]\n",
    "    df = g[1]\n",
    "    for n in NINPUTS:\n",
    "        df_sub=df[list(df.columns[:n])+[OUTPUT]]\n",
    "        x_train,y_train,y_train_scale,delta,z_train,diff = get_train_data(df_sub)\n",
    "      \n",
    "        ## TRAIN RNN Codes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(1):\n",
    "#     print('j: '+str(j))\n",
    "#     sort_index = []\n",
    "#     sele_col = 2\n",
    "#     ### sele_col: 0-4\n",
    "#     for i in range(all_para.shape[0]):\n",
    "#         if all_para[i,sele_col] in sele_key_list:\n",
    "#             sort_index.append(sele_key_list.index(all_para[i,sele_col]))\n",
    "# #     sort_index = np.insert(sort_index,0,23)\n",
    "\n",
    "#     final_RNN_x = RNN_x[:,:,sort_index]\n",
    "#     all_result=[]\n",
    "#     all_RMSE=[]\n",
    "#     all_MAE = []\n",
    "#     for i in np.arange(4,28,4):\n",
    "#         print('i: '+str(i))\n",
    "#         ### i is the number of parameters taken to construct the training model\n",
    "#         partial_data = train_data(final_RNN_x,i)\n",
    "#         #### the model is trained based on RNN_y_scale_reverse\n",
    "#         RNN_x_train,RNN_x_test,RNN_y_train,RNN_y_test=train_test_split(partial_data[:,:,:], RNN_y_scale_reverse, test_size=0.2, random_state=40)\n",
    "#     #     RNN_x_train,RNN_x_test,RNN_y_train,RNN_y_test=train_test_split(partial_data[:,:,:],RNN_y, test_size=0.2, random_state=40)\n",
    "#         RNN_model = get_RNN_model(RNN_x_train.shape[2])\n",
    "#         RNN_model.fit(RNN_x_train,RNN_y_train,batch_size=30,verbose=False,epochs=200)\n",
    "#         kdp = KerasDPprediction(RNN_model)\n",
    "#         y_test_pred=kdp.predict(RNN_x_test,1000)\n",
    "#         all_result.append(y_test_pred)\n",
    "#         mean_y_test_pred = np.mean(y_test_pred,axis=0)\n",
    "#         RMSE =np.sqrt(np.mean((mean_y_test_pred-RNN_y_test)**2)) \n",
    "#         MAE = np.mean(np.abs(mean_y_test_pred-RNN_y_test))\n",
    "\n",
    "#         all_RMSE.append(RMSE)\n",
    "#         all_MAE.append(MAE)\n",
    "#     all_all_result.append(all_result)\n",
    "#     all_all_RMSE.append(all_RMSE)\n",
    "#     all_all_MAE.append(all_MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54a95f",
   "metadata": {},
   "source": [
    "### Step 3d: Assessment of Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21184a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_all_MAE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616e950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
